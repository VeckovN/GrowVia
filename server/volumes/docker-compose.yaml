#docker -d ->detach mode : see all logs in console
#docker compose up -d redis mongodb posgres rabbitmq elasticsearch kibana

version: '3.9'

services:
  redis:
    container_name: redis_container #locally enter the contaier with this name
    image: redis:alpine #lightweigh version
    restart: always
    ports:
      #insideContainer port: outsideContainer port (we use to access the container)
      - '6379:6379'
    command: redis-server --loglevel warning
     #when we run redis localy (DB) the data must be store somewhere -> In Volumes
    #volumes like storage -> where the data is stored
    volumes:
    #locate 'docker-volumes/cache:' and map it to :/data
    #the docker-volumes and /cache/ will be created on service run (we don't need to create it)
      - ./docker-volumes/cache:/data
    #/data we get from redit and want to map it to the '/docker-volumes/cache' on local machine
  mongodb:
    container_name: mongodb_container
    image: mongo:latest
    restart: always
    ports: 
     - 27017:27017
    volumes:
        #this /data: could be anything (we name it 'data')
      - ./docker-volumes/data:/data/db

  postgres:
    container_name: postgres_container
    image: postgres
    restart: always
    environment:
     - POSTGRES_USER=growvia
     - POSTGRES_PASSWORD=growviapass
     - POSTGRES_DB=intiall_db
    ports:
      - '5432:5432'
    volumes:
     - ./docker-volumes/postgres:/var/lib/postgresql

  #not storing any data -no volumes 
  rabbitmq:
    container_name: rabbitmq_container
    image: rabbitmq:4.0.5-management-alpine
    restart: always
    environment:
      - RABBITMQ_DEFAULT_USER=growvia
      - RABBITMQ_DEFAULT_PASS=growviapassword
    ports:
      #AMQP protocol port (to access from The app)
      - '5672:5672'
      #management port (to access Management UI )
      - '15672:15672'

  elasticsearch:
    container_name: elasticsearch_container
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.0
    restart: always
    environment:
      ES_JAVA_OPTS: -Xmx1g -Xms1g
      bootstrap.memory_lock: "true"
      discovery.type: single-node #sufficient for local dev
      xpack.security.enabled: "false" #security requeries to have a valid SSL sertificate ->HTTPS (no for local dev)
      xpack.security.authc.api_key.enabled: "true"
      xpack.monitoring.collection.enabled: "true"
      xpack.security.enrollment.enabled: "true"
    ports:
      - 9300:9300 # this is for another node (When isn't discovery.type: single-node)
      - 9200:9200 #Access elasticsearch api  
    volumes:
     - ./docker-volumes/elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - elastic
  
  kibana:
    container_name: kibana_container
    image: docker.elastic.co/kibana/kibana:8.17.0
    # image: docker.elastic.co/kibana/kibana:8.11.0
    restart: always
    environment:
      - ELASTICSEARCH_HOSTS=["http://elasticsearch_container:9200"] #form this kibana will get access to this service -> elasticsearch_container 
    ports:
      - 5601:5601
    networks:
      - elastic
    volumes:
      - ./kibana.yml:/usr/share/kibana/config/kibana.yml:ro #:ro -> readOnly
    depends_on:
      - elasticsearch #start only when elasticSearch running

networks:
  elastic:
    name: elastic